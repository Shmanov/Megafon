{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "У нас появился запрос из отдела продаж и маркетинга. Как вы знаете «МегаФон» предлагает обширный набор различных услуг своим абонентам. При этом разным пользователям интересны разные услуги. Поэтому необходимо построить  алгоритм, который для каждой пары пользователь-услуга определит вероятность подключения услуги.\n",
    "Данные\n",
    "В качестве исходных данных вам будет доступна информация об отклике абонентов на предложение подключения одной из услуг. Каждому пользователю может быть сделано несколько предложений в разное время, каждое из которых он может или принять, или отклонить.\n",
    "Отдельным набором данных будет являться нормализованный анонимизированный набор признаков, характеризующий профиль потребления абонента. Эти данные привязаны к определенному времени, поскольку профиль абонента может меняться с течением времени.\n",
    "#### Данные: \n",
    "train и test разбиты по периодам – на train доступно 4 месяцев, а на test отложен последующий месяц. \n",
    "Итого, в качестве входных данных будут представлены:\n",
    "\n",
    "●\tdata_train.csv: id, vas_id, buy_time, target\n",
    "\n",
    "●\tfeatures.csv.zip: id, <feature_list> \n",
    "\n",
    "#### Тестовый набор:\n",
    "\n",
    "●\tdata_test.csv: id, vas_id, buy_time\n",
    "\n",
    "target - целевая переменная, где 1 означает подключение услуги, 0 - абонент не подключил услугу соответственно. \n",
    "buy_time - время покупки, представлено в формате timestamp, для работы с этим столбцом понадобится функция datetime.fromtimestamp из модуля datetime.\n",
    "id - идентификатор абонента\n",
    "vas_id - подключаемая услуга\n",
    "Примечание: Размер файла features.csv в распакованном виде весит 20 гб, для работы  с ним можно воспользоваться pandas.read_csv, либо можно воспользоваться библиотекой Dask.\n",
    "Метрика\n",
    "Скоринг будет осуществляться функцией f1, невзвешенным образом, как например делает функция sklearn.metrics.f1_score(…, average=’macro’)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_PATH = 'data/features.csv'\n",
    "DATA_TRAIN_PATH = 'data/data_train.csv'\n",
    "DATA_TEST_PATH = 'data/data_test.csv'\n",
    "DATA_TRAIN_MERGE_PATH = 'data/data_train_merge.csv'\n",
    "DATA_TEST_MERGE_PATH = 'data/data_test_merge.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Загрузим файл с признаками клиента. Файл весит более 20Гб, прочитаем его разбив на куски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv(FEATURES_PATH,chunksize = 100000, iterator = True, delimiter='\\\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Загрузим обучающий набор "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_TRAIN_PATH,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>buy_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>540968</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1537131600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1454121</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1531688400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2458816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1534107600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3535012</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1535922000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1693214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1535922000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  vas_id    buy_time  target\n",
       "0           0   540968     8.0  1537131600     0.0\n",
       "1           1  1454121     4.0  1531688400     0.0\n",
       "2           2  2458816     1.0  1534107600     0.0\n",
       "3           3  3535012     5.0  1535922000     0.0\n",
       "4           4  1693214     1.0  1535922000     0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### buy_time - время покупки, представлено в формате timestamp, для работы с этим столбцом понадобится функция datetime.fromtimestamp из модуля datetime.\n",
    "##### target - целевая переменная, где 1 означает подключение услуги, 0 - абонент не подключил услугу соответственно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 831653 entries, 0 to 831652\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  831653 non-null  int64  \n",
      " 1   id          831653 non-null  int64  \n",
      " 2   vas_id      831653 non-null  float64\n",
      " 3   buy_time    831653 non-null  int64  \n",
      " 4   target      831653 non-null  float64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 31.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Отлично! Видим, что DataFrame содержит 831653 записей и нет пропущенных значений. Проверим на уникальность значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    831653\n",
       "id            806613\n",
       "vas_id             8\n",
       "buy_time          26\n",
       "target             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### target - целевая переменная имеет бинарный признак, id - идентификатор абонента имеет не уникальные значения, свидетельствует о том, что клиенту было предложено несколько попыток с предложением о подключении услуги. 8 услуг, 26 дат с предложением услуг."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Избавимся от дублей если они есть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Отфильтруем DataFrame профилей абонентов по id из обучающего набора. Иными словами выберем только те профили клиентов которые присутствуют в обучающем наборе. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_new = pd.DataFrame() # пустой фрейм\n",
    "for chunk_iter in df_features: # цикл по кускам dataframe\n",
    "  filtr_id = chunk_iter['id'].isin(df_train.id) # создаём фильтр по куску  \n",
    "  chunk = chunk_iter[filtr_id] # фильтруем записи в куске\n",
    "  df_features_new = pd.concat([df_features_new,chunk]) # склеиваем отфильтрованные куски в dataframe \n",
    "  #print(chunk_iter)  \n",
    "  #print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 834168 entries, 13 to 4512521\n",
      "Columns: 255 entries, id to 252\n",
      "dtypes: float64(253), int64(2)\n",
      "memory usage: 1.6 GB\n"
     ]
    }
   ],
   "source": [
    "df_features_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  dataframe значительно уменьшился, до 1.6 Gb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_new['buy_time'] = df_features_new.buy_time.apply(datetime.fromtimestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['buy_time'] = df_train.buy_time.apply(datetime.fromtimestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>buy_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>540968</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2018-09-17 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1454121</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-07-16 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2458816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-08-13 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3535012</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-09-03 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1693214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-09-03 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  vas_id            buy_time  target\n",
       "0           0   540968     8.0 2018-09-17 01:00:00     0.0\n",
       "1           1  1454121     4.0 2018-07-16 01:00:00     0.0\n",
       "2           2  2458816     1.0 2018-08-13 01:00:00     0.0\n",
       "3           3  3535012     5.0 2018-09-03 01:00:00     0.0\n",
       "4           4  1693214     1.0 2018-09-03 01:00:00     0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by=['buy_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_new = df_features_new.sort_values(by=['buy_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_merge = pd.merge_asof(df_train, df_features_new, on='buy_time', by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "vas_id           0\n",
       "buy_time         0\n",
       "target           0\n",
       "0           422929\n",
       "             ...  \n",
       "248         422929\n",
       "249         422929\n",
       "250         422929\n",
       "251         422929\n",
       "252         422929\n",
       "Length: 257, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_merge.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### При слиянии получилось большое количестово колонок с пустыми значениями. Удалим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_merge = dt_merge.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          397259\n",
       "vas_id           8\n",
       "buy_time        26\n",
       "target           2\n",
       "0            32842\n",
       "             ...  \n",
       "248           1583\n",
       "249            213\n",
       "250           1398\n",
       "251            209\n",
       "252             19\n",
       "Length: 257, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_merge.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_merge.to_csv(DATA_TRAIN_MERGE_PATH, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FileProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_merge = FileProcessing.preparing(DATA_TEST_PATH, FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_merge.to_csv(DATA_TRAIN_MERGE_PATH, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
